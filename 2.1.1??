
# Optional generic preliminaries:
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!

# Required packages for this exercise (you may add more if you want to).
require(rjags)
require(coda)
source("DBDA2E-utilities.R")

#------------------------   Model 1: exam scores   ----------------------------


# THE DATA
n = 40
k = c(19, 20, 16, 23, 22, 30, 38, 29, 34, 35, 35, 32, 37, 36, 33)
p = length(k)
#z = rep(0, p)

# THE MODEL
exammodel1.string = "
  model {
    ## Prior
    
      phi ~ dunif(0.5, 1)
      psi = 0.5
      for (i in 1:p) {
      z[i] ~ dbern(0.5)
      theta[i] <- equals(z[i],0)*psi + equals(z[i],1)*phi
}

    ## Likelihood
      for (i in 1:p){
      k[i] ~ dbin(theta[i], n)
  }
}

"

# JAGS usually reads models from a text file; here we use a string as a fake file.   
exammodel1.spec = textConnection(exammodel1.string)

# SAMPLING PARAMETERS
niter = 10000
nchains = 4

# Construct the object containing both the model specification as well as the data and some sampling parameters.
jagsmodel1 <- jags.model(exammodel1.spec,
                   data = list(
                      'k' = k,
                      'n' = n,
                      'p' = p),
                   n.chains = nchains)

# Collect samples to approximate the posterior distribution.
model1samples = coda.samples(jagsmodel1,
                           c('z'), # which variables do you want to model
                           n.iter = niter)
plotPost(model1samples[,'z'], xlab = 'z')
diagMCMC(codaObject = model1samples, parName = 'z')
